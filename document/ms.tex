\documentclass[12pt,preprint]{aastex}

% has to be before amssymb it seems
\usepackage{color,hyperref}
\definecolor{linkcolor}{rgb}{0,0,0.5}
\hypersetup{colorlinks=true,linkcolor=linkcolor,citecolor=linkcolor,
            filecolor=linkcolor,urlcolor=linkcolor}

\usepackage{url}
\usepackage{algorithmic,algorithm}
\usepackage{multirow}

\usepackage{listings}
\definecolor{lbcolor}{rgb}{0.9,0.9,0.9}
\lstset{language=Python,
        basicstyle=\footnotesize\ttfamily,
        showspaces=false,
        showstringspaces=false,
        tabsize=2,
        breaklines=false,
        breakatwhitespace=true,
        identifierstyle=\ttfamily,
        keywordstyle=\bfseries\color[rgb]{0.133,0.545,0.133},
        commentstyle=\color[rgb]{0.133,0.545,0.133},
        stringstyle=\color[rgb]{0.627,0.126,0.941},
    }

\input{vars}

\begin{document}

\title{%
The \kplr\ Catalog:
Systematic probabilistic parameter estimation for every \kepler\ planet candidate
}

\newcommand{\nyu}{2}
\newcommand{\mpia}{3}
\author{%
    Daniel~Foreman-Mackey\altaffilmark{1,\nyu},
    David~W.~Hogg\altaffilmark{\nyu,\mpia},
    \etal
}
\altaffiltext{1}{To whom correspondence should be addressed:
                        \url{danfm@nyu.edu}}
\altaffiltext{\nyu}{Center for Cosmology and Particle Physics,
                        Department of Physics, New York University,
                        4 Washington Place, New York, NY, 10003, USA}
\altaffiltext{\mpia}{Max-Planck-Institut f\"ur Astronomie,
                        K\"onigstuhl 17, D-69117 Heidelberg, Germany}

\begin{abstract} % should be aims, methods, results
As precise as \kepler\ is,
it provides only probabilistic information
about transiting companions in the lightcurves of stars.
The official \kepler\ best-fit values for the parameters
(periods, radii ratios, durations, impact parameters)
contain some known biases,
are not associated with full uncertainty propagation,
and cannot be used as the basis of any probabilistic population analysis.

Here we provide a catalog of probabilistic constraints on the physical parameters
for every planet candidate (KOI) from the \kepler\ transiting
planet search.
Using a physically motivated generative model with flat ``interim'' priors, we
draw samples from the posterior probability distribution conditioned on all
the available light curves from \kepler\ Quarters 0 through 16.
We release both the catalog values and full $16384$-element posterior
samplings for each system.
We compare our results to the existing KOI Catalog and find xxx.
Using these samplings, we demonstrate a computationally tractable hierarchical
inference technique for simultaneously modeling the exoplanet radius
distribution and the selection function of the \kepler\ survey and pipeline.
When applied to a sample of cool stars with well constrained properties, we
find yyy.

Access to the catalog is available on-line at \url{http://data.kplr.co} and
the code is available---under the terms of the MIT license---at
\url{https://github.com/dfm/kois}.

\end{abstract}

\keywords{% CUT THESE DOWN TO SIX
  astronomical~databases:~miscellaneous
  ---
  catalogs
  ---
  eclipses
  ---
  methods:~statistical
  ---
  planetary~systems
  ---
  planets~and~satellites:~detection
  ---
  planets~and~satellites:~fundamental~parameters
  ---
  stars:~statistics
  ---
  surveys
}

\section{Introduction}

So probabilistically righteous.

TODO: Talk about the philosophy of interim priors here.

TODO: Justify the use of non-physically motivated parameters and relate this
to the idea of sufficient statistics.

\section{Data}

The goal of this project is to propagate any information about exoplanets from
the \kepler\ light curves into a form that is more user friendly.
We target the list of all \kepler\ Objects of Interest (KOIs) listed on the
Exoplanet Archive\footnote{FIXME: URL} as planet candidates and confirmed
planets from quarters xxx--yyy.
Some of these candidates are certainly so-called false positives but we treat
them all equally so that the user can freely make their own target selection.
As our raw dataset, we start with the MAP-PDC light curves (CITE) provided by
MAST\footnote{FIXME: URL} and perform further preconditioning or
``de-trending'' to remove any remaining astrophysical or instrumental noise.

\paragraph{Target selection}
We downloaded the full list KOIs from the exoplanet archive using the \kplr\
Python module\footnote{\url{http://dan.iel.fm/kplr}} on SOME DATE and filtered
the list to only include planet candidates and confirmed planets as listed in
the database.
This list corresponds to the catalog from (SOME CITATION) generated by
searching the light curves from quarters xxx--yyy using the Transiting Planet
Search (TPS) module and then hand vetted (CITE).

\paragraph{Data selection}
Next, we downloaded all available PDC light curves (both short and long
cadence) for a given target and selected all data points within 4 transit
durations---as determined by the KOI catalog---of a transit.

\paragraph{Preconditioning}
Then, we mask the data within 1.5 transit durations and fit the maximum
likelihood line to the remaining data points.
Finally, we divide the full window by this model to generate a ``de-trended''
light curve.
This procedure has been applied successfully in the literature (Carter ETC
CITE) and it should be less destructive to transit signals than alternative
techniques like median filtering and ``robust'' regression.

\section{Model}

A model, from our perspective, is a parameterized probability for the data,
the likelihood function, and a prior probability distribution over parameters.
We will also divide the likelihood further into a \emph{deterministic physical
generative model} and a \emph{stochastic noise model}.
The form for each of these model components can be freely chosen and in the
next sections, we'll justify our specific choices.
In short, we assume independent Gaussian noise, a Mandel \& Agol (CITE) like
limb darkened light curve, and simple interim priors.

\paragraph{Noise model}
The noise in the light curves generated by the Kepler pipeline result from a
large collection of effects.
There are both astrophysical sources (stellar variability, \etc) instrumental
effects (photon noise, temperature and pointing variations, \etc).
The exact effect of each of these effects is complicated by the aperture
photometry procedure and all of the preconditioning steps discussed above.
Despite these complications, we'll assume that the error bars produced by the
Kepler pipeline are good estimates and that they are distributed independently
and normally.
This is a reasonable assumption because TODO.

\paragraph{Generative model}
For this project, we assume a quadratic limb darkened light curve model
following Mandel \& Agol (CITE) and integrate over exposure time (Kipping
CITE, Appendix XXXX).
Since we don't want to be dependent on specific stellar parameters and since
we would like to make it easy to apply any new stellar catalogs, we don't use
physical orbits.
Instead, we parameterize the orbit using only ``observable'' parameters.
In particular, we use, for the star, the mean stellar flux \fstar, and the
parameters \qone\ and \qtwo\ of a quadratic limb darkening profile
(parameterized following Kipping CITE).
For each companion, we parameterize the orbit using period \period, epoch
\epoch, transit duration \duration, radius ratio \ror, and impact parameter
\impact.
\Tab{parameters} specifies the parameters used in this \paper\ and the
interim priors used.

\paragraph{Interim priors}
For simplicity---and that is the main goal when using interim priors---we
chose to model the prior probabilities for each parameter as uniform
distributions in the linear parameter except the radius ratio.
For this distribution, we use
\begin{eqnarray}
p(\ror) &\propto& \left \{ \begin{array}{ll}
1/\ror^2 & \ror_\mathrm{min} \le \ror \le 1 \\
0 & \mathrm{otherwise} \\
\end{array}\right.
\end{eqnarray}
where we conservatively choose $\ror_\mathrm{min} = 10^{-4}$.

\Tab{parameters} lists the exact interim priors applied to each parameter.

\begin{deluxetable}{lclcc}
\tabletypesize{\footnotesize}
\tablecolumns{3}
\tablewidth{0pt}

\tablecaption{%
The parameters of the generative model and their associated interim priors.
\tablabel{parameters}}

\tablehead{%
\colhead{Symbol} &
\colhead{Unit} &
\colhead{Description} &
\colhead{Range} &
\colhead{Prior}
}

\startdata

\fstar & --- & mean stellar flux & $[0, 2]$ & Uniform \\
\qone & --- & first limb darkening coefficient & $[0, 1]$ & Uniform \\
\vspace{0.5cm}
\qtwo & --- & second limb darkening coefficient & $[0, 1]$ & Uniform \\

\period & days & orbital period & $[0, 1000]$\tablenotemark{a} & Uniform \\
\epoch & days & center time of reference transit & $[0, 1000]$\tablenotemark{a}
       & Uniform \\
\duration & days & transit duration\tablenotemark{b} & $[0, 10]$ & Uniform \\
\ror & --- & radius ratio & $[10^{-4}, 1]$ & $1/\ror^2$ \\
\impact & --- & impact parameter & $[0, 2]$ & Uniform \\

\enddata

\tablenotetext{a}{%
In practice, we use more constraining priors on \period\ and \epoch\
because the initial values are very close to correct in most cases but this
doesn't affect the results.
}
\tablenotetext{b}{%
The transit duration is defined as the time between initial contact and
final contact.
}
\end{deluxetable}

\section{Comments}

\begin{itemize}
\item{Limb darkening}
\item{Integration over exposure time}
\end{itemize}

\section{Sampling method}

We sampled the posterior probability in equation SOMEEQN using the affine
invariant ensemble sampler (CITE: GW, emcee).
This method is perfect for this project because it tends to require very
little tuning even when applied to new datasets.

\paragraph{Ensemble specifications}
We run with 48 walkers on 24 cores on the BuTinah cluster at NYUAD.

\paragraph{Initialization}
We start sampling in a \emph{tiny} isotropic Gaussian ball (HOW BIG) centered
at the parameters given in the KOI catalog.
Then, we run 2000 iterations of MCMC and re-sample the walkers in a similarly
time Gaussian ball around the maximum probability point seen in that run.

\paragraph{Production chain}
Finally we run the production chain---re-estimating the integrated
auto-correlation time for each parameter---until we have at least $128 \times
N_\mathrm{walkers}$ independent samples for ever parameter.

\paragraph{Analysis of convergence}


\section{Results}


\section{The empirical radius distribution}

The problem of determining the empirical distribution of exoplanet radii
without taking selection effects into account (see Foreman-Mackey \etal\ in
prep), can be written as a hierarchical inference problem.
We have samples from the posterior probability distribution
\begin{eqnarray}
z^{(j)} &\sim& p(z\,|\,x,\,\alpha_0)
\end{eqnarray}
where $z$ is the radius ratio, $x$ is the light curve, and $\alpha_0$ are the
parameters of the interim prior $p(z\,|\,\alpha_0)$.
Instead, we would like to compute and/or sample the parameters describing the
distribution of physical radii $p(r\,|\,\alpha)$.
To do this, we must compute the \emph{marginalized likelihood}
\begin{eqnarray}\eqlabel{marg-like}
p(x,\,\hat{R}\,|\,\alpha) &=&
    \int \dd r\dd R\dd z\,\prod_n p(R_n)\,p(\hat{R}_n\,|\,R_n)
        \prod_k p(r_{nk}\,|\,\alpha)\,p(z_{nk}\,|\,R_n,\,r_{nk})\,
                p(x\,|\,z_{nk}) \quad.
\end{eqnarray}
We can rewrite the inner term---using the fact that
$p(z_{nk}\,|\,R_n,\,r_{nk})\equiv\delta(r_{nk}-R_n\cdot z_{nk})$---as
\begin{eqnarray}
p_{nk}(x\,|\,R_n,\,\alpha)&=&
\int \dd r_{nk}\dd z_{nk}\,p(r_{nk}\,|\,\alpha)\,p(z_{nk}\,|\,R_n,\,r_{nk})\,
        p(x\,|\,z_{nk}) \nonumber\\
&=&
\int \dd z_{nk}\,p(z_{nk} \cdot R_n\,|\,\alpha)\,p(x\,|\,z_{nk}) \nonumber\\
&=&
\int \dd z_{nk}\,p(z_{nk}\cdot R_n\,|\,\alpha)\,p(x\,|\,z_{nk})\,
\frac{p(z_{nk}\,|\,x,\,\alpha_0)}{p(z_{nk}\,|\,x,\,\alpha_0)} \nonumber\\
&\propto&
\int \dd z_{nk}\,\frac{p(z_{nk}\cdot R_n\,|\,\alpha)}{p(z_{nk}\,|\,\alpha_0)}\,
p(z_{nk}\,|\,x,\,\alpha_0) \nonumber\\
&\approx&
\frac{1}{J_{nk}}
\sum_j \frac{p(z_{nk}^{(j)}\cdot R_n\,|\,\alpha)}{p(z_{nk}^{(j)}\,|\,\alpha_0)}
\end{eqnarray}

The integral over stellar radius can also be approximated using posterior
samples
\begin{eqnarray}
R^{(l)} &\sim& p(R\,|\,\hat{R}) \quad.
\end{eqnarray}
Here, we're not trying to simultaneously infer the distribution of stellar
parameters.
This simplifies matters and the full integral in \eq{marg-like} can be
approximated as
\begin{eqnarray}
\frac{p(x,\,\hat{R}\,|\,\alpha)}{p(x,\,\hat{R}\,|\,\alpha_0)}
&\approx& \prod_n \frac{1}{L_n} \sum_{l=1}^{L_n} \prod_k
\frac{1}{J_{nk}} \sum_{j=1}^{J_{nk}}
\frac{p(z_{nk}^{(j)}\cdot R_n\,|\,\alpha)}{p(z_{nk}^{(j)}\,|\,\alpha_0)}
\quad.
\end{eqnarray}
This ratio can now be computed efficiently for different values $\alpha$ and
optimized or you can set priors $p(\alpha)$ and sample.

\acknowledgments
It is a pleasure to thank
    Tom Barclay (NASA Ames),
    Tim Morton (Princeton),
    Jon Swift (Caltech),
    \ldots
for helpful contributions to the ideas and code presented here.
This work made use of the BuTinah cluster supported by NYU HPC (FIXME).
This project was partially supported by the NSF (grant AST-0908357), and NASA
(grant NNX08AJ48G).

\newcommand{\arxiv}[1]{\href{http://arxiv.org/abs/#1}{arXiv:#1}}
\begin{thebibliography}{}\raggedright

\bibitem[Tremaine \& Dong(2012)]{tremaine}
Tremaine, S., \& Dong, S.\ 2012, \aj, 143, 94
\arxiv{1106.5403}

\bibitem[Winn(2010)]{winn}
Winn, J.~N.\ 2010, \arxiv{1001.2010}

\end{thebibliography}

\appendix

\section{Recursive exposure time integration}

It is well known (Kipping, others, ASK BARCLAY) that integrating the
exposure time when computing a generative light curve model makes a huge
difference especially for short period orbits.
Kipping argues for the use of a resampling technique.
For computational efficiency and robustness to \emph{contact point
discontinuities}, we developed and used an adaptive recursive algorithm.
This algorithm refines the resampling grid around points where where second
derivative of the light curve function is largest.
This means that the base grid can be extremely coarse.

The basic idea is that we have some function $f(t)$ that returns the
instantaneous flux of the system at time $t$ but we would like to compute the
integrated flux over an exposure time \texp
\begin{eqnarray}
f_\mathrm{int}(t_0;\texp) &=& \int_{t_0-\texp/2}^{t_0+\texp/2} f(t) \dd t
    \quad.
\end{eqnarray}
Following Kipping, this can be approximated as
\begin{eqnarray}
f_\mathrm{int}(t_0;\texp) &\approx&
    \frac{f(t_0-\texp/3)+f(t_0)+f(t_0+\texp/3)}{3} \quad.
\end{eqnarray}
We extend this by recursively defining this approximation as
\begin{eqnarray}
f_\mathrm{int}(t_0;\texp) &\approx&
    \frac{f_\mathrm{int}(t_0-\texp/3;\texp/3)+f_\mathrm{int}(t_0;\texp/3)
          +f_\mathrm{int}(t_0+\texp/3;\texp/3)}{3}
\end{eqnarray}
where the recursive depth is set by a tolerance on
\begin{eqnarray}
\left | \frac{f(t_0-\texp/3)-2\,f(t_0)+f(t_0+\texp/3)}
             {f(t_0-\texp/3)-f(t_0+\texp/3)} \right | &\le& \epsilon
\end{eqnarray}
where $\epsilon$ is a free parameter quantifying the required accuracy of the
method.


\end{document}
